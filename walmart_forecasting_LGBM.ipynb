{
 "cells": [
  {
   "attachments": {
    "bd9ff145-526c-47c0-9b21-6846c248477e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "14cfee9b-7ca7-4e0b-b0ce-953a1cef458d",
   "metadata": {},
   "source": [
    "# Walmart M5 Forecasting Solution - Approach 1 & Results\n",
    "\n",
    "## 1. Objective\n",
    "We aim to forecast daily sales for Walmart stores across multiple categories and locations over two 28-day periods:\n",
    "- **Validation**: `d_1914–d_1941`\n",
    "- **Evaluation**: `d_1942–d_1969`\n",
    "\n",
    "The final output is a submission file combining both predictions in the required M5 competition format.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Data Processing & Memory Optimization\n",
    "- Joined sales, pricing and calendar data\n",
    "- Filtered data for Year >= 2013 to reduce memory usage\n",
    "- Applied a custom `reduce_mem_usage()` function to minimize RAM usage via downcasting.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Feature Engineering\n",
    "We engineered several meaningful features to help the model learn temporal and pricing patterns:\n",
    "\n",
    "### Lag Features\n",
    "- `sales_lag_1`, `sales_lag_7`, `sales_lag_14`, `sales_lag_28`\n",
    "\n",
    "### Rolling Mean & Std\n",
    "- Windows: 7, 14, 28, 60, 180 days\n",
    "- Features: `rolling_mean_*`, `rolling_std_*`\n",
    "\n",
    "### Price Dynamics\n",
    "- `price_max`, `price_min`, `price_std`\n",
    "- `price_norm`, `price_momentum`\n",
    "\n",
    "### Time-Based Features\n",
    "- Day (`tm_d`), Day of Week (`tm_dw`), Weekend (`tm_w_end`), Week of Month (`tm_wm`), Month (`tm_m`), Year (`tm_y`)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Cross-Validation Strategy\n",
    "Time-based validation folds were used to preserve temporal structure.\n",
    "\n",
    "```text\n",
    "Fold 1: Train d_1–d_1577 → Predict d_1578–d_1605  \n",
    "Fold 2: Train d_1–d_1829 → Predict d_1830–d_1857  \n",
    "Fold 3: Train d_1–d_1857 → Predict d_1858–d_1885  \n",
    "Fold 4: Train d_1–d_1885 → Predict d_1886–d_1913  \n",
    "Fold 5: Train d_1–d_1913 → Predict d_1914–d_1941 (Validation)  \n",
    "```\n",
    "\n",
    "Models were trained for each **store × 7-day week block** to localize patterns and increase granularity.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Modeling Approach\n",
    "- Used **LightGBM** with **Tweedie regression** (`tweedie_variance_power = 1.1`) to handle zero-inflated demand.\n",
    "- GPU-accelerated (`device: gpu`) for fast training.\n",
    "- One model trained per:\n",
    "  - **Store ID**\n",
    "  - **7-day window** within the 28-day horizon\n",
    "- **Final Holdout RMSE (d1914–1941): 0.0611**\n",
    "---\n",
    "\n",
    "## 6. Forecasting Strategy\n",
    "\n",
    "### Validation (d_1914–1941)\n",
    "- Used CV-trained models\n",
    "- Calculated RMSE per fold and overall\n",
    "\n",
    "### Evaluation (d_1942–1969)\n",
    "- Extended base data with future rows using calendar + price\n",
    "\n",
    "## 7. Kaggle Submission\n",
    "![image.png](attachment:bd9ff145-526c-47c0-9b21-6846c248477e.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252be913-e253-4a3f-94c9-7fc05739dc12",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931e0063-2f47-47dc-aeb2-be2152342199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc  # Garbage collection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # To keep output clean\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ed444b-1715-465d-8ab0-fe42302a8fa3",
   "metadata": {},
   "source": [
    "## Helper Function to Downcast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f22e826-3490-45e0-8332-93bb8895b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Function to Downcast\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    \"\"\" \n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Memory usage reduced from {start_mem:.2f} MB to {end_mem:.2f} MB ({100*(start_mem-end_mem)/start_mem:.1f}% reduction)\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af66d6a-1b1b-455c-8b64-187c94b21b17",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc11c041-db4f-4e3f-bd41-b45f72d5e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n",
      "Memory usage reduced from 6335.64 MB to 4211.76 MB (33.5% reduction)\n",
      "Data downcasted and memory cleaned successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the sales_long_recent CSV (normal way)\n",
    "\n",
    "sales_long_recent = pd.read_csv('sales_recent.csv')  # ← Change path if needed\n",
    "\n",
    "print(\"CSV loaded successfully!\")\n",
    "\n",
    "sales_long_recent = reduce_mem_usage(sales_long_recent)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# Ensure 'd' column is numeric\n",
    "if sales_long_recent['d'].dtype == object:\n",
    "    sales_long_recent['d'] = sales_long_recent['d'].str.replace('d_', '').astype(int)\n",
    "\n",
    "print(\"Data downcasted and memory cleaned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1fb339-4846-4034-8551-190693df3a3d",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba7a06-bb9d-4920-b4b6-60c6b91b790b",
   "metadata": {},
   "source": [
    "### Lag features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e106f4b5-abc8-4074-aafc-1079e8088480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag features \n",
    "\n",
    "def create_lag_features(df, lags=[1, 7, 14, 28]):\n",
    "    for lag in lags:\n",
    "        df[f'sales_lag_{lag}'] = df.groupby('id')['sales'].shift(lag)\n",
    "    print(\"Shape after transformation:\", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd56838-98ad-4aeb-8276-8bc329126c5b",
   "metadata": {},
   "source": [
    "### Rolling features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2b5cd7f-50ce-42e3-9873-4521620daecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling features \n",
    "def create_rolling_features(df, windows=[7, 14, 28, 60, 180]):\n",
    "    for window in windows:\n",
    "        df[f'rolling_mean_{window}'] = (\n",
    "            df.groupby('id')['sales'].shift(1).rolling(window).mean()\n",
    "        )\n",
    "        df[f'rolling_std_{window}'] = (\n",
    "            df.groupby('id')['sales'].shift(1).rolling(window).std()\n",
    "        )\n",
    "    print(\"Shape after transformation:\", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e059c-8aa1-4563-979d-cfefe8ec3961",
   "metadata": {},
   "source": [
    "### Calendar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd714577-adc7-44b4-8897-6df50f4d5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calendar features \n",
    "def create_calendar_features(df):\n",
    "    df['tm_d'] = df['date'].dt.day\n",
    "    df['tm_dw'] = df['date'].dt.weekday\n",
    "    df['tm_w_end'] = (df['tm_dw'] >= 5).astype(np.int8)\n",
    "    df['tm_wm'] = df['date'].dt.day // 7\n",
    "    df['tm_m'] = df['date'].dt.month\n",
    "    df['tm_y'] = df['date'].dt.year\n",
    "    print(\"Shape after transformation:\", df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c34bedc-1f38-4d95-9d07-3fe3a6c62eac",
   "metadata": {},
   "source": [
    "### Price Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d221c51-ee1e-4af8-863d-7332d4fb4acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price Features \n",
    "def create_price_features(df):\n",
    "    df['price_max'] = df.groupby(['store_id', 'item_id'])['sell_price'].transform('max')\n",
    "    df['price_min'] = df.groupby(['store_id', 'item_id'])['sell_price'].transform('min')\n",
    "    df['price_std'] = df.groupby(['store_id', 'item_id'])['sell_price'].transform('std')\n",
    "    df['price_norm'] = df['sell_price'] / df['price_max']\n",
    "    df['price_momentum'] = df['sell_price'] / df.groupby(['store_id', 'item_id'])['sell_price'].shift(1)\n",
    "    print(\"Shape after transformation:\", df.shape)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f1b532-3f50-4d61-867b-73e9a2f9d42a",
   "metadata": {},
   "source": [
    "### Handle event columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e68de3d1-da83-4488-9ec5-d44d2c381408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle event columns \n",
    "def encode_event_columns(df):\n",
    "    event_cols = ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']\n",
    "    for col in event_cols:\n",
    "        if col in df.columns and df[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "            print(f\"Encoded {col}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2222f995-07a5-4677-bf38-939cb7fcab09",
   "metadata": {},
   "source": [
    "### Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7cd6e2d-e709-4735-9a1c-44609dea08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering \n",
    "def run_feature_engineering(df):\n",
    "    print(\"Creating lag features...\")\n",
    "    df = create_lag_features(df)\n",
    "    \n",
    "    print(\"Creating rolling features...\")\n",
    "    df = create_rolling_features(df)\n",
    "    \n",
    "    print(\"Creating calendar features...\")\n",
    "    if not np.issubdtype(df['date'].dtype, np.datetime64):\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "    df = create_calendar_features(df)\n",
    "    \n",
    "    print(\"Creating price features...\")\n",
    "    df = create_price_features(df)\n",
    "\n",
    "    print(\"Cleaning up event columns...\")\n",
    "    df = encode_event_columns(df)\n",
    "\n",
    "    print(\"All features created successfully!\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34e0d801-1529-428d-ada6-f80042647781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features...\n",
      "Shape after transformation: (37746620, 26)\n",
      "Creating rolling features...\n",
      "Shape after transformation: (37746620, 36)\n",
      "Creating calendar features...\n",
      "Shape after transformation: (37746620, 42)\n",
      "Creating price features...\n",
      "Shape after transformation: (37746620, 47)\n",
      "Cleaning up event columns...\n",
      "Encoded event_name_1\n",
      "Encoded event_type_1\n",
      "Encoded event_name_2\n",
      "Encoded event_type_2\n",
      "All features created successfully!\n",
      "Shape after dropping NaNs: (33930028, 47)\n"
     ]
    }
   ],
   "source": [
    "# full feature creation pipeline\n",
    "sales_long_recent = run_feature_engineering(sales_long_recent)\n",
    "\n",
    "# Drop rows with NaNs created by lags and rolling windows\n",
    "sales_long_recent = sales_long_recent.dropna()\n",
    "sales_long_recent = sales_long_recent.reset_index(drop=True)\n",
    "\n",
    "print(\"Shape after dropping NaNs:\", sales_long_recent.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64330be3-46f7-4c82-a315-1f39fc5919cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "rolling_std_180    0\n",
       "rolling_mean_7     0\n",
       "rolling_std_7      0\n",
       "rolling_mean_14    0\n",
       "rolling_std_14     0\n",
       "rolling_mean_28    0\n",
       "rolling_std_28     0\n",
       "rolling_mean_60    0\n",
       "rolling_std_60     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_long_recent.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e915b5b-b6b8-459c-956e-5876682408e0",
   "metadata": {},
   "source": [
    "### Define target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a541840-327e-49a9-a3fe-125a6028eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 38\n",
      "Some features: ['d', 'sales', 'wday', 'month', 'year', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2', 'snap_CA']\n"
     ]
    }
   ],
   "source": [
    "# Define target\n",
    "TARGET = 'sales'\n",
    "\n",
    "# Define columns to ignore during training\n",
    "ignored_columns = [\n",
    "    'id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id',  # identifiers\n",
    "    'date', 'wm_yr_wk', 'weekday'  # time columns\n",
    "    'sales'  # target\n",
    "]\n",
    "\n",
    "# Define feature list\n",
    "FEATURES = [col for col in sales_long_recent.columns if col not in ignored_columns]\n",
    "FEATURES = [f for f in FEATURES if f != 'weekday']\n",
    "\n",
    "print(\"Number of features:\", len(FEATURES))\n",
    "print(\"Some features:\", FEATURES[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da353fa-be1e-4408-96f6-3a2d324c025b",
   "metadata": {},
   "source": [
    "## Regression Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86ee832-f4df-4573-89b8-cb8004a79e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold ranges (excluding final holdout)\n",
    "FOLD_DAYS = [1577, 1829, 1857, 1885, 1913]\n",
    "\n",
    "# Week blocks (for 28-day prediction horizon)\n",
    "WEEK_BLOCKS = [\n",
    "    (1, 7),\n",
    "    (8, 14),\n",
    "    (15, 21),\n",
    "    (22, 28)\n",
    "]\n",
    "\n",
    "def create_folds(df, fold_days, val_length=28):\n",
    "    if df['d'].dtype == object:\n",
    "        df['d'] = df['d'].str.replace('d_', '').astype(int)\n",
    "\n",
    "    folds = []\n",
    "    for fold_day in fold_days:\n",
    "        train_idx = df[df['d'] <= fold_day].index\n",
    "        valid_idx = df[(df['d'] > fold_day) & (df['d'] <= fold_day + val_length)].index\n",
    "        folds.append((train_idx, valid_idx))\n",
    "    return folds\n",
    "\n",
    "\n",
    "def train_cv_and_evaluate(df, features, target):\n",
    "    folds = create_folds(df, FOLD_DAYS)\n",
    "    store_ids = df['store_id'].unique()\n",
    "    models = {}\n",
    "    fold_scores = {i: [] for i in range(len(folds))}  # RMSEs per fold for all blocks\n",
    "\n",
    "    for store in store_ids:\n",
    "        print(f\"\\n=== Store: {store} ===\")\n",
    "        store_df = df[df['store_id'] == store]\n",
    "\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            print(f\"  Week Block: {block_key}\")\n",
    "            models[block_key] = []\n",
    "\n",
    "            for fold_idx, (train_idx, valid_idx) in enumerate(folds):\n",
    "                fold_day = FOLD_DAYS[fold_idx]\n",
    "\n",
    "                # No slicing of train data — use full train period\n",
    "                train_data = store_df.loc[train_idx.intersection(store_df.index)]\n",
    "\n",
    "                # Validation for just the current week block\n",
    "                min_d = fold_day + w_start\n",
    "                max_d = fold_day + w_end\n",
    "                valid_data = store_df[(store_df['d'] >= min_d) & (store_df['d'] <= max_d)]\n",
    "\n",
    "                # If validation data is missing or too small, skip\n",
    "                if len(train_data) < 100 or train_data[target].nunique() <= 1:\n",
    "                    print(f\"    Skipping Fold {fold_idx+1} - insufficient or constant training target\")\n",
    "                    models[block_key].append(None)\n",
    "                    continue\n",
    "\n",
    "                if len(valid_data) == 0 or valid_data[target].nunique() <= 1:\n",
    "                    print(f\"    Skipping Fold {fold_idx+1} - invalid validation target\")\n",
    "                    models[block_key].append(None)\n",
    "                    continue\n",
    "\n",
    "                X_train = train_data[features]\n",
    "                y_train = train_data[target]\n",
    "                X_valid = valid_data[features]\n",
    "                y_valid = valid_data[target]\n",
    "\n",
    "                dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "                dvalid = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "                params = {\n",
    "                    'objective': 'tweedie',\n",
    "                    'metric': 'rmse',\n",
    "                    'tweedie_variance_power': 1.1,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'learning_rate': 0.05,\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'colsample_bytree': 0.75,\n",
    "                    'max_depth': -1,\n",
    "                    'num_leaves': 64,\n",
    "                    'min_child_samples': 100,\n",
    "                    'verbose': -1\n",
    "                }\n",
    "\n",
    "                try:\n",
    "                    model = lgb.train(\n",
    "                        params,\n",
    "                        dtrain,\n",
    "                        num_boost_round=500,\n",
    "                        valid_sets=[dtrain, dvalid]\n",
    "                    )\n",
    "                    preds = model.predict(X_valid)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "                    fold_scores[fold_idx].append(rmse)\n",
    "                    models[block_key].append(model)\n",
    "                    print(f\"    Fold {fold_idx+1} RMSE: {rmse:.4f}\")\n",
    "                except lgb.basic.LightGBMError as e:\n",
    "                    print(f\"    Fold {fold_idx+1} failed for {block_key}: {e}\")\n",
    "                    models[block_key].append(None)\n",
    "                    continue\n",
    "\n",
    "    print(\"\\nFold-wise Average RMSE across all stores and week blocks:\")\n",
    "    final_rmse_per_fold = {}\n",
    "    for i, scores in fold_scores.items():\n",
    "        if scores:\n",
    "            avg_rmse = np.mean(scores)\n",
    "            final_rmse_per_fold[i + 1] = avg_rmse\n",
    "            print(f\"  Fold {i + 1}: {avg_rmse:.4f}\")\n",
    "        else:\n",
    "            final_rmse_per_fold[i + 1] = None\n",
    "            print(f\"  Fold {i + 1}: No valid models\")\n",
    "\n",
    "    return models\n",
    "\n",
    "def evaluate_holdout_rmse(cv_models, df, features, target):\n",
    "    print(\"\\nEvaluating on final holdout (d1914–1941)...\")\n",
    "\n",
    "    holdout_df = df[(df['d'] >= 1914) & (df['d'] <= 1941)].copy()\n",
    "    store_ids = holdout_df['store_id'].unique()\n",
    "    all_preds = []\n",
    "    all_truth = []\n",
    "\n",
    "    for store in store_ids:\n",
    "        store_df = holdout_df[holdout_df['store_id'] == store]\n",
    "\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            block_df = store_df[(store_df['d'] >= 1913 + w_start) & (store_df['d'] <= 1913 + w_end)]\n",
    "\n",
    "            if block_df.empty or block_key not in cv_models:\n",
    "                continue\n",
    "\n",
    "            valid_models = [m for m in cv_models[block_key] if m is not None]\n",
    "            if not valid_models:\n",
    "                print(f\"  Skipping {block_key} - no valid trained models\")\n",
    "                continue\n",
    "\n",
    "            X = block_df[features]\n",
    "            y = block_df[target]\n",
    "\n",
    "            preds = np.mean([m.predict(X) for m in valid_models], axis=0)\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_truth.extend(y.values)\n",
    "\n",
    "    if not all_preds:\n",
    "        print(\"No predictions made on holdout — all models missing or invalid.\")\n",
    "        return None\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_truth, all_preds))\n",
    "    print(f\"\\nFinal Holdout RMSE (d1914–1941): {rmse:.4f}\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b9ae745-40ef-4fab-9fd1-323fb2670520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Store: CA_1 ===\n",
      "  Week Block: CA_1_F01_F07\n",
      "    Fold 1 RMSE: 0.0582\n",
      "    Fold 2 RMSE: 0.0684\n",
      "    Fold 3 RMSE: 0.0756\n",
      "    Fold 4 RMSE: 0.0732\n",
      "    Fold 5 RMSE: 0.0578\n",
      "  Week Block: CA_1_F08_F14\n",
      "    Fold 1 RMSE: 0.0680\n",
      "    Fold 2 RMSE: 0.0684\n",
      "    Fold 3 RMSE: 0.0537\n",
      "    Fold 4 RMSE: 0.0700\n",
      "    Fold 5 RMSE: 0.0619\n",
      "  Week Block: CA_1_F15_F21\n",
      "    Fold 1 RMSE: 0.0996\n",
      "    Fold 2 RMSE: 0.0875\n",
      "    Fold 3 RMSE: 0.0903\n",
      "    Fold 4 RMSE: 0.0652\n",
      "    Fold 5 RMSE: 0.0627\n",
      "  Week Block: CA_1_F22_F28\n",
      "    Fold 1 RMSE: 0.0920\n",
      "    Fold 2 RMSE: 0.0563\n",
      "    Fold 3 RMSE: 0.0584\n",
      "    Fold 4 RMSE: 0.0533\n",
      "    Fold 5 RMSE: 0.0871\n",
      "\n",
      "=== Store: CA_2 ===\n",
      "  Week Block: CA_2_F01_F07\n",
      "    Fold 1 RMSE: 0.0528\n",
      "    Fold 2 RMSE: 0.0609\n",
      "    Fold 3 RMSE: 0.0442\n",
      "    Fold 4 RMSE: 0.0527\n",
      "    Fold 5 RMSE: 0.1711\n",
      "  Week Block: CA_2_F08_F14\n",
      "    Fold 1 RMSE: 0.5461\n",
      "    Fold 2 RMSE: 0.1014\n",
      "    Fold 3 RMSE: 0.1278\n",
      "    Fold 4 RMSE: 0.0557\n",
      "    Fold 5 RMSE: 0.1402\n",
      "  Week Block: CA_2_F15_F21\n",
      "    Fold 1 RMSE: 0.2739\n",
      "    Fold 2 RMSE: 0.0529\n",
      "    Fold 3 RMSE: 0.0860\n",
      "    Fold 4 RMSE: 0.0520\n",
      "    Fold 5 RMSE: 0.0594\n",
      "  Week Block: CA_2_F22_F28\n",
      "    Fold 1 RMSE: 0.0960\n",
      "    Fold 2 RMSE: 0.0834\n",
      "    Fold 3 RMSE: 0.1487\n",
      "    Fold 4 RMSE: 0.0800\n",
      "    Fold 5 RMSE: 0.0571\n",
      "\n",
      "=== Store: CA_3 ===\n",
      "  Week Block: CA_3_F01_F07\n",
      "    Fold 1 RMSE: 0.2071\n",
      "    Fold 2 RMSE: 0.1035\n",
      "    Fold 3 RMSE: 0.1025\n",
      "    Fold 4 RMSE: 0.0739\n",
      "    Fold 5 RMSE: 0.0693\n",
      "  Week Block: CA_3_F08_F14\n",
      "    Fold 1 RMSE: 1.0526\n",
      "    Fold 2 RMSE: 0.0931\n",
      "    Fold 3 RMSE: 0.0858\n",
      "    Fold 4 RMSE: 0.0802\n",
      "    Fold 5 RMSE: 0.0672\n",
      "  Week Block: CA_3_F15_F21\n",
      "    Fold 1 RMSE: 0.5798\n",
      "    Fold 2 RMSE: 0.0815\n",
      "    Fold 3 RMSE: 0.0773\n",
      "    Fold 4 RMSE: 0.0864\n",
      "    Fold 5 RMSE: 0.0665\n",
      "  Week Block: CA_3_F22_F28\n",
      "    Fold 1 RMSE: 0.1787\n",
      "    Fold 2 RMSE: 0.0721\n",
      "    Fold 3 RMSE: 0.0993\n",
      "    Fold 4 RMSE: 0.0682\n",
      "    Fold 5 RMSE: 0.0752\n",
      "\n",
      "=== Store: CA_4 ===\n",
      "  Week Block: CA_4_F01_F07\n",
      "    Fold 1 RMSE: 0.0421\n",
      "    Fold 2 RMSE: 0.0402\n",
      "    Fold 3 RMSE: 0.0359\n",
      "    Fold 4 RMSE: 0.0469\n",
      "    Fold 5 RMSE: 0.0321\n",
      "  Week Block: CA_4_F08_F14\n",
      "    Fold 1 RMSE: 0.0326\n",
      "    Fold 2 RMSE: 0.0438\n",
      "    Fold 3 RMSE: 0.0291\n",
      "    Fold 4 RMSE: 0.0286\n",
      "    Fold 5 RMSE: 0.0291\n",
      "  Week Block: CA_4_F15_F21\n",
      "    Fold 1 RMSE: 0.0658\n",
      "    Fold 2 RMSE: 0.0294\n",
      "    Fold 3 RMSE: 0.0339\n",
      "    Fold 4 RMSE: 0.0275\n",
      "    Fold 5 RMSE: 0.0398\n",
      "  Week Block: CA_4_F22_F28\n",
      "    Fold 1 RMSE: 0.0479\n",
      "    Fold 2 RMSE: 0.0331\n",
      "    Fold 3 RMSE: 0.0417\n",
      "    Fold 4 RMSE: 0.0311\n",
      "    Fold 5 RMSE: 0.0398\n",
      "\n",
      "=== Store: TX_1 ===\n",
      "  Week Block: TX_1_F01_F07\n",
      "    Fold 1 RMSE: 0.0434\n",
      "    Fold 2 RMSE: 0.0611\n",
      "    Fold 3 RMSE: 0.0476\n",
      "    Fold 4 RMSE: 0.0647\n",
      "    Fold 5 RMSE: 0.0493\n",
      "  Week Block: TX_1_F08_F14\n",
      "    Fold 1 RMSE: 0.0890\n",
      "    Fold 2 RMSE: 0.0635\n",
      "    Fold 3 RMSE: 0.0482\n",
      "    Fold 4 RMSE: 0.0522\n",
      "    Fold 5 RMSE: 0.0426\n",
      "  Week Block: TX_1_F15_F21\n",
      "    Fold 1 RMSE: 0.1048\n",
      "    Fold 2 RMSE: 0.1279\n",
      "    Fold 3 RMSE: 0.0470\n",
      "    Fold 4 RMSE: 0.0462\n",
      "    Fold 5 RMSE: 0.1065\n",
      "  Week Block: TX_1_F22_F28\n",
      "    Fold 1 RMSE: 0.2485\n",
      "    Fold 2 RMSE: 0.0430\n",
      "    Fold 3 RMSE: 0.0612\n",
      "    Fold 4 RMSE: 0.0565\n",
      "    Fold 5 RMSE: 0.0623\n",
      "\n",
      "=== Store: TX_2 ===\n",
      "  Week Block: TX_2_F01_F07\n",
      "    Fold 1 RMSE: 0.0525\n",
      "    Fold 2 RMSE: 0.0832\n",
      "    Fold 3 RMSE: 0.0522\n",
      "    Fold 4 RMSE: 0.0575\n",
      "    Fold 5 RMSE: 0.0531\n",
      "  Week Block: TX_2_F08_F14\n",
      "    Fold 1 RMSE: 0.0602\n",
      "    Fold 2 RMSE: 0.0788\n",
      "    Fold 3 RMSE: 0.0538\n",
      "    Fold 4 RMSE: 0.0639\n",
      "    Fold 5 RMSE: 0.1247\n",
      "  Week Block: TX_2_F15_F21\n",
      "    Fold 1 RMSE: 0.1184\n",
      "    Fold 2 RMSE: 0.0787\n",
      "    Fold 3 RMSE: 0.0792\n",
      "    Fold 4 RMSE: 0.0484\n",
      "    Fold 5 RMSE: 0.0589\n",
      "  Week Block: TX_2_F22_F28\n",
      "    Fold 1 RMSE: 0.1376\n",
      "    Fold 2 RMSE: 0.0674\n",
      "    Fold 3 RMSE: 0.0705\n",
      "    Fold 4 RMSE: 0.0601\n",
      "    Fold 5 RMSE: 0.0473\n",
      "\n",
      "=== Store: TX_3 ===\n",
      "  Week Block: TX_3_F01_F07\n",
      "    Fold 1 RMSE: 0.0605\n",
      "    Fold 2 RMSE: 0.0775\n",
      "    Fold 3 RMSE: 0.0505\n",
      "    Fold 4 RMSE: 0.0563\n",
      "    Fold 5 RMSE: 0.0522\n",
      "  Week Block: TX_3_F08_F14\n",
      "    Fold 1 RMSE: 0.1054\n",
      "    Fold 2 RMSE: 0.0685\n",
      "    Fold 3 RMSE: 0.0707\n",
      "    Fold 4 RMSE: 0.0495\n",
      "    Fold 5 RMSE: 0.0564\n",
      "  Week Block: TX_3_F15_F21\n",
      "    Fold 1 RMSE: 0.1053\n",
      "    Fold 2 RMSE: 0.0666\n",
      "    Fold 3 RMSE: 0.0560\n",
      "    Fold 4 RMSE: 0.0507\n",
      "    Fold 5 RMSE: 0.0675\n",
      "  Week Block: TX_3_F22_F28\n",
      "    Fold 1 RMSE: 0.2188\n",
      "    Fold 2 RMSE: 0.0569\n",
      "    Fold 3 RMSE: 0.0668\n",
      "    Fold 4 RMSE: 0.0539\n",
      "    Fold 5 RMSE: 0.0704\n",
      "\n",
      "=== Store: WI_1 ===\n",
      "  Week Block: WI_1_F01_F07\n",
      "    Fold 1 RMSE: 0.0410\n",
      "    Fold 2 RMSE: 0.0442\n",
      "    Fold 3 RMSE: 0.0594\n",
      "    Fold 4 RMSE: 0.0486\n",
      "    Fold 5 RMSE: 0.0382\n",
      "  Week Block: WI_1_F08_F14\n",
      "    Fold 1 RMSE: 0.0444\n",
      "    Fold 2 RMSE: 0.0440\n",
      "    Fold 3 RMSE: 0.0488\n",
      "    Fold 4 RMSE: 0.0450\n",
      "    Fold 5 RMSE: 0.0435\n",
      "  Week Block: WI_1_F15_F21\n",
      "    Fold 1 RMSE: 0.0516\n",
      "    Fold 2 RMSE: 0.0521\n",
      "    Fold 3 RMSE: 0.0414\n",
      "    Fold 4 RMSE: 0.0400\n",
      "    Fold 5 RMSE: 0.0385\n",
      "  Week Block: WI_1_F22_F28\n",
      "    Fold 1 RMSE: 0.0465\n",
      "    Fold 2 RMSE: 0.0550\n",
      "    Fold 3 RMSE: 0.0597\n",
      "    Fold 4 RMSE: 0.0375\n",
      "    Fold 5 RMSE: 0.0520\n",
      "\n",
      "=== Store: WI_2 ===\n",
      "  Week Block: WI_2_F01_F07\n",
      "    Fold 1 RMSE: 0.0574\n",
      "    Fold 2 RMSE: 0.2680\n",
      "    Fold 3 RMSE: 0.5280\n",
      "    Fold 4 RMSE: 0.0862\n",
      "    Fold 5 RMSE: 0.0673\n",
      "  Week Block: WI_2_F08_F14\n",
      "    Fold 1 RMSE: 0.0946\n",
      "    Fold 2 RMSE: 0.1999\n",
      "    Fold 3 RMSE: 0.1586\n",
      "    Fold 4 RMSE: 0.2551\n",
      "    Fold 5 RMSE: 0.2368\n",
      "  Week Block: WI_2_F15_F21\n",
      "    Fold 1 RMSE: 0.0967\n",
      "    Fold 2 RMSE: 0.2280\n",
      "    Fold 3 RMSE: 0.1669\n",
      "    Fold 4 RMSE: 0.1095\n",
      "    Fold 5 RMSE: 0.1330\n",
      "  Week Block: WI_2_F22_F28\n",
      "    Fold 1 RMSE: 0.0927\n",
      "    Fold 2 RMSE: 0.0559\n",
      "    Fold 3 RMSE: 0.0738\n",
      "    Fold 4 RMSE: 0.0836\n",
      "    Fold 5 RMSE: 0.0965\n",
      "\n",
      "=== Store: WI_3 ===\n",
      "  Week Block: WI_3_F01_F07\n",
      "    Fold 1 RMSE: 0.0496\n",
      "    Fold 2 RMSE: 0.1249\n",
      "    Fold 3 RMSE: 0.1014\n",
      "    Fold 4 RMSE: 0.0804\n",
      "    Fold 5 RMSE: 0.0599\n",
      "  Week Block: WI_3_F08_F14\n",
      "    Fold 1 RMSE: 0.0588\n",
      "    Fold 2 RMSE: 0.1255\n",
      "    Fold 3 RMSE: 0.0982\n",
      "    Fold 4 RMSE: 0.1027\n",
      "    Fold 5 RMSE: 0.1612\n",
      "  Week Block: WI_3_F15_F21\n",
      "    Fold 1 RMSE: 0.0899\n",
      "    Fold 2 RMSE: 0.0948\n",
      "    Fold 3 RMSE: 0.1501\n",
      "    Fold 4 RMSE: 0.0654\n",
      "    Fold 5 RMSE: 0.0806\n",
      "  Week Block: WI_3_F22_F28\n",
      "    Fold 1 RMSE: 0.1202\n",
      "    Fold 2 RMSE: 0.1034\n",
      "    Fold 3 RMSE: 0.0918\n",
      "    Fold 4 RMSE: 0.1559\n",
      "    Fold 5 RMSE: 0.0804\n",
      "\n",
      "Fold-wise Average RMSE across all stores and week blocks:\n",
      "  Fold 1: 0.1420\n",
      "  Fold 2: 0.0836\n",
      "  Fold 3: 0.0868\n",
      "  Fold 4: 0.0679\n",
      "  Fold 5: 0.0749\n",
      "\n",
      "Evaluating on final holdout (d1914–1941)...\n",
      "\n",
      "Final Holdout RMSE (d1914–1941): 0.0768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07677859328895906"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_models = train_cv_and_evaluate(\n",
    "    sales_long_recent,\n",
    "    features=FEATURES,\n",
    "    target=TARGET\n",
    ")\n",
    "\n",
    "evaluate_holdout_rmse(\n",
    "    cv_models,\n",
    "    df=sales_long_recent,\n",
    "    features=FEATURES,\n",
    "    target=TARGET\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22ebbe78-c872-4af8-b531-c5008762ee3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44040143-a990-4d0a-93bf-99351ccb2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_holdout_rmse(cv_models, df, features, target, return_preds=False):\n",
    "    print(\"\\nEvaluating on final holdout (d1914–1941)...\")\n",
    "\n",
    "    holdout_df = df[(df['d'] >= 1914) & (df['d'] <= 1941)].copy()\n",
    "    store_ids = holdout_df['store_id'].unique()\n",
    "    all_preds = []\n",
    "    all_truth = []\n",
    "    output_rows = []\n",
    "\n",
    "    for store in store_ids:\n",
    "        store_df = holdout_df[holdout_df['store_id'] == store]\n",
    "\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            block_df = store_df[(store_df['d'] >= 1913 + w_start) & (store_df['d'] <= 1913 + w_end)]\n",
    "\n",
    "            if block_df.empty or block_key not in cv_models:\n",
    "                continue\n",
    "\n",
    "            valid_models = [m for m in cv_models[block_key] if m is not None]\n",
    "            if not valid_models:\n",
    "                print(f\"  Skipping {block_key} - no valid trained models\")\n",
    "                continue\n",
    "\n",
    "            X = block_df[features]\n",
    "            y = block_df[target]\n",
    "\n",
    "            preds = np.mean([m.predict(X) for m in valid_models], axis=0)\n",
    "\n",
    "            block_df['prediction'] = preds\n",
    "            output_rows.append(block_df[['id', 'd', 'prediction']])\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_truth.extend(y.values)\n",
    "\n",
    "    if not all_preds:\n",
    "        print(\"No predictions made on holdout — all models missing or invalid.\")\n",
    "        return None\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_truth, all_preds))\n",
    "    print(f\"\\nFinal Holdout RMSE (d1914–1941): {rmse:.4f}\")\n",
    "\n",
    "    if return_preds:\n",
    "        return pd.concat(output_rows, axis=0)\n",
    "    else:\n",
    "        return rmse\n",
    "\n",
    "def extend_with_future(df, calendar_df, price_df, forecast_start=1942, forecast_end=1969):\n",
    "    print(\"Creating future evaluation grid (d1942–1969)...\")\n",
    "    base_cols = ['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id']\n",
    "    last_day = df['d'].max()\n",
    "    id_cols = df[df['d'] == last_day][base_cols].drop_duplicates()\n",
    "\n",
    "    future_days = pd.DataFrame({'d': list(range(forecast_start, forecast_end + 1))})\n",
    "    id_expanded = id_cols.assign(key=1).merge(future_days.assign(key=1), on='key').drop('key', axis=1)\n",
    "\n",
    "    if df['d'].dtype == object:\n",
    "        id_expanded['d'] = 'd_' + id_expanded['d'].astype(str)\n",
    "        calendar_df['d'] = calendar_df['d'].astype(str)\n",
    "    else:\n",
    "        id_expanded['d'] = id_expanded['d'].astype(int)\n",
    "        calendar_df['d'] = pd.to_numeric(calendar_df['d'], errors='coerce')\n",
    "\n",
    "    extended_df = pd.merge(id_expanded, calendar_df, on='d', how='left')\n",
    "    extended_df = pd.merge(extended_df, price_df, on=['store_id', 'item_id', 'wm_yr_wk'], how='left')\n",
    "    extended_df['sales'] = 0\n",
    "\n",
    "    for col in ['event_name_1', 'event_type_1', 'event_name_2', 'event_type_2']:\n",
    "        if col in extended_df.columns:\n",
    "            extended_df[col] = extended_df[col].fillna('none')\n",
    "\n",
    "    print(f\"Created {len(extended_df)} future forecast rows\")\n",
    "    return extended_df\n",
    "\n",
    "def forecast_final_period(cv_models, df, features):\n",
    "    forecast_rows = []\n",
    "    for store in df['store_id'].unique():\n",
    "        store_df = df[df['store_id'] == store]\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            min_d = 1941 + w_start\n",
    "            max_d = 1941 + w_end\n",
    "            block_df = store_df[(store_df['d'] >= min_d) & (store_df['d'] <= max_d)].copy()\n",
    "\n",
    "            if block_df.empty:\n",
    "                print(f\"  Skipping {block_key} - no data for d_{min_d} to d_{max_d}\")\n",
    "                continue\n",
    "            if block_key not in cv_models:\n",
    "                print(f\"  Skipping {block_key} - no model key found\")\n",
    "                continue\n",
    "\n",
    "            valid_models = [m for m in cv_models[block_key] if m is not None]\n",
    "            if not valid_models:\n",
    "                print(f\"  Skipping {block_key} - all models are None\")\n",
    "                continue\n",
    "\n",
    "            X = block_df[features]\n",
    "            preds = np.mean([m.predict(X) for m in valid_models], axis=0)\n",
    "            block_df['prediction'] = preds\n",
    "            forecast_rows.append(block_df[['id', 'd', 'prediction']])\n",
    "\n",
    "    if not forecast_rows:\n",
    "        print(\"No forecast blocks available for evaluation period (d1942–1969)\")\n",
    "        return pd.DataFrame(columns=['id', 'd', 'prediction'])\n",
    "\n",
    "    return pd.concat(forecast_rows, axis=0)\n",
    "\n",
    "def pivot_predictions(pred_df, start_day, label):\n",
    "    pred_df = pred_df.copy()\n",
    "    pred_df['F'] = pred_df['d'] - start_day + 1\n",
    "    pred_df = pred_df[['id', 'F', 'prediction']]\n",
    "    pred_df = pred_df.pivot(index='id', columns='F', values='prediction')\n",
    "    pred_df.columns = [f\"F{int(c)}\" for c in pred_df.columns]\n",
    "    pred_df = pred_df.reset_index()\n",
    "    pred_df['id'] = pred_df['id'].str.replace('_evaluation', f'_{label}')\n",
    "    return pred_df\n",
    "\n",
    "def generate_submission(cv_models, df, features, target, future_df, output_path=\"final_submission.csv\"):\n",
    "    val_preds = evaluate_holdout_rmse(cv_models, df, features, target, return_preds=True)\n",
    "    eval_preds = forecast_final_period(cv_models, future_df, features)\n",
    "    val_df = pivot_predictions(val_preds, start_day=1914, label='validation')\n",
    "    eval_df = pivot_predictions(eval_preds, start_day=1942, label='evaluation')\n",
    "    submission = pd.concat([val_df, eval_df], axis=0)\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"Submission file saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ce1647c-a142-4388-86d6-1f66ee931dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating future evaluation grid (d1942–1969)...\n",
      "Created 853720 future forecast rows\n",
      "Creating lag features...\n",
      "Shape after transformation: (853720, 26)\n",
      "Creating rolling features...\n",
      "Shape after transformation: (853720, 36)\n",
      "Creating calendar features...\n",
      "Shape after transformation: (853720, 42)\n",
      "Creating price features...\n",
      "Shape after transformation: (853720, 47)\n",
      "Cleaning up event columns...\n",
      "Encoded event_name_1\n",
      "Encoded event_type_1\n",
      "Encoded event_name_2\n",
      "Encoded event_type_2\n",
      "All features created successfully!\n",
      "\n",
      "Evaluating on final holdout (d1914–1941)...\n",
      "\n",
      "Final Holdout RMSE (d1914–1941): 0.0768\n",
      "Submission file saved to final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "calendar = pd.read_csv('calendar.csv')\n",
    "sell_prices = pd.read_csv('sell_prices.csv')\n",
    "\n",
    "# Extend future period\n",
    "future_df = extend_with_future(sales_long_recent, calendar, sell_prices)\n",
    "\n",
    "# Apply feature engineering to future data\n",
    "future_df = run_feature_engineering(future_df)\n",
    "\n",
    "# Generate final submission with both validation and evaluation forecasts\n",
    "generate_submission(cv_models, sales_long_recent, FEATURES, TARGET, future_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f70a830f-a084-4518-bb36-9cace7f2e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_models(df, features, target):\n",
    "    print(\"\\nTraining final models on full d_1 to d_1941 range for evaluation forecast...\")\n",
    "    store_ids = df['store_id'].unique()\n",
    "    final_models = {}\n",
    "\n",
    "    full_train_df = df[df['d'] <= 1941]\n",
    "\n",
    "    for store in store_ids:\n",
    "        print(f\"\\n=== Store: {store} ===\")\n",
    "        store_df = full_train_df[full_train_df['store_id'] == store]\n",
    "\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            print(f\"  Final Block Model: {block_key}\")\n",
    "\n",
    "            X_train = store_df[features]\n",
    "            y_train = store_df[target]\n",
    "\n",
    "            dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "\n",
    "            params = {\n",
    "                'objective': 'tweedie',\n",
    "                'metric': 'rmse',\n",
    "                'tweedie_variance_power': 1.1,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': 0.05,\n",
    "                'subsample': 0.75,\n",
    "                'subsample_freq': 1,\n",
    "                'colsample_bytree': 0.75,\n",
    "                'max_depth': -1,\n",
    "                'num_leaves': 64,\n",
    "                'min_child_samples': 100,\n",
    "                'verbose': -1\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                model = lgb.train(params, dtrain, num_boost_round=500)\n",
    "                final_models[block_key] = model\n",
    "            except lgb.basic.LightGBMError as e:\n",
    "                print(f\"    Failed to train model for {block_key}: {e}\")\n",
    "                final_models[block_key] = None\n",
    "\n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20740d65-9517-4195-86e6-139ecf251503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating future evaluation grid (d1942–1969)...\n",
      "Created 853720 future forecast rows\n",
      "\n",
      "Training final models on full d_1 to d_1941 range for evaluation forecast...\n",
      "\n",
      "=== Store: CA_1 ===\n",
      "  Final Block Model: CA_1_F01_F07\n",
      "  Final Block Model: CA_1_F08_F14\n",
      "  Final Block Model: CA_1_F15_F21\n",
      "  Final Block Model: CA_1_F22_F28\n",
      "\n",
      "=== Store: CA_2 ===\n",
      "  Final Block Model: CA_2_F01_F07\n",
      "  Final Block Model: CA_2_F08_F14\n",
      "  Final Block Model: CA_2_F15_F21\n",
      "  Final Block Model: CA_2_F22_F28\n",
      "\n",
      "=== Store: CA_3 ===\n",
      "  Final Block Model: CA_3_F01_F07\n",
      "  Final Block Model: CA_3_F08_F14\n",
      "  Final Block Model: CA_3_F15_F21\n",
      "  Final Block Model: CA_3_F22_F28\n",
      "\n",
      "=== Store: CA_4 ===\n",
      "  Final Block Model: CA_4_F01_F07\n",
      "  Final Block Model: CA_4_F08_F14\n",
      "  Final Block Model: CA_4_F15_F21\n",
      "  Final Block Model: CA_4_F22_F28\n",
      "\n",
      "=== Store: TX_1 ===\n",
      "  Final Block Model: TX_1_F01_F07\n",
      "  Final Block Model: TX_1_F08_F14\n",
      "  Final Block Model: TX_1_F15_F21\n",
      "  Final Block Model: TX_1_F22_F28\n",
      "\n",
      "=== Store: TX_2 ===\n",
      "  Final Block Model: TX_2_F01_F07\n",
      "  Final Block Model: TX_2_F08_F14\n",
      "  Final Block Model: TX_2_F15_F21\n",
      "  Final Block Model: TX_2_F22_F28\n",
      "\n",
      "=== Store: TX_3 ===\n",
      "  Final Block Model: TX_3_F01_F07\n",
      "  Final Block Model: TX_3_F08_F14\n",
      "  Final Block Model: TX_3_F15_F21\n",
      "  Final Block Model: TX_3_F22_F28\n",
      "\n",
      "=== Store: WI_1 ===\n",
      "  Final Block Model: WI_1_F01_F07\n",
      "  Final Block Model: WI_1_F08_F14\n",
      "  Final Block Model: WI_1_F15_F21\n",
      "  Final Block Model: WI_1_F22_F28\n",
      "\n",
      "=== Store: WI_2 ===\n",
      "  Final Block Model: WI_2_F01_F07\n",
      "  Final Block Model: WI_2_F08_F14\n",
      "  Final Block Model: WI_2_F15_F21\n",
      "  Final Block Model: WI_2_F22_F28\n",
      "\n",
      "=== Store: WI_3 ===\n",
      "  Final Block Model: WI_3_F01_F07\n",
      "  Final Block Model: WI_3_F08_F14\n",
      "  Final Block Model: WI_3_F15_F21\n",
      "  Final Block Model: WI_3_F22_F28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "future_df = extend_with_future(sales_long_recent, calendar, sell_prices)\n",
    "final_models = train_final_models(sales_long_recent, FEATURES, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d299d612-9435-4f86-8688-e15c7b9f119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission(final_models, df, features, target, future_df, output_path=\"final_submission.csv\"):\n",
    "    val_preds = evaluate_holdout_rmse(final_models, df, features, target, return_preds=True)\n",
    "    eval_preds = forecast_final_period_single(final_models, future_df, features)\n",
    "    val_df = pivot_predictions(val_preds, start_day=1914, label='validation')\n",
    "    eval_df = pivot_predictions(eval_preds, start_day=1942, label='evaluation')\n",
    "    submission = pd.concat([val_df, eval_df], axis=0)\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"Submission file saved to {output_path}\")\n",
    "    \n",
    "def evaluate_holdout_rmse(cv_models, df, features, target, return_preds=False):\n",
    "    print(\"\\nEvaluating on final holdout (d1914–1941)...\")\n",
    "\n",
    "    holdout_df = df[(df['d'] >= 1914) & (df['d'] <= 1941)].copy()\n",
    "    store_ids = holdout_df['store_id'].unique()\n",
    "    all_preds = []\n",
    "    all_truth = []\n",
    "    output_rows = []\n",
    "\n",
    "    for store in store_ids:\n",
    "        store_df = holdout_df[holdout_df['store_id'] == store]\n",
    "\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            block_df = store_df[(store_df['d'] >= 1913 + w_start) & (store_df['d'] <= 1913 + w_end)]\n",
    "\n",
    "            if block_df.empty or block_key not in cv_models:\n",
    "                continue\n",
    "\n",
    "            model = cv_models[block_key]\n",
    "            if isinstance(model, list):\n",
    "                model = [m for m in model if m is not None]\n",
    "                if not model:\n",
    "                    print(f\"  Skipping {block_key} - all models are None\")\n",
    "                    continue\n",
    "                preds = np.mean([m.predict(block_df[features]) for m in model], axis=0)\n",
    "            else:\n",
    "                if model is None:\n",
    "                    print(f\"  Skipping {block_key} - model is None\")\n",
    "                    continue\n",
    "                preds = model.predict(block_df[features])\n",
    "\n",
    "            block_df['prediction'] = preds\n",
    "            output_rows.append(block_df[['id', 'd', 'prediction']])\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_truth.extend(block_df[target].values)\n",
    "\n",
    "    if not all_preds:\n",
    "        print(\"No predictions made on holdout — all models missing or invalid.\")\n",
    "        return None\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(all_truth, all_preds))\n",
    "    print(f\"\\nFinal Holdout RMSE (d1914–1941): {rmse:.4f}\")\n",
    "\n",
    "    if return_preds:\n",
    "        return pd.concat(output_rows, axis=0)\n",
    "    else:\n",
    "        return rmse\n",
    "\n",
    "def forecast_final_period_single(cv_models, df, features):\n",
    "    forecast_rows = []\n",
    "    for store in df['store_id'].unique():\n",
    "        store_df = df[df['store_id'] == store]\n",
    "        for (w_start, w_end) in WEEK_BLOCKS:\n",
    "            block_key = f\"{store}_F{w_start:02d}_F{w_end:02d}\"\n",
    "            min_d = 1941 + w_start\n",
    "            max_d = 1941 + w_end\n",
    "            block_df = store_df[(store_df['d'] >= min_d) & (store_df['d'] <= max_d)].copy()\n",
    "\n",
    "            if block_df.empty:\n",
    "                print(f\"  Skipping {block_key} - no data for d_{min_d} to d_{max_d}\")\n",
    "                continue\n",
    "            if block_key not in cv_models:\n",
    "                print(f\"  Skipping {block_key} - no model key found\")\n",
    "                continue\n",
    "\n",
    "            model = cv_models[block_key]\n",
    "            if isinstance(model, list):\n",
    "                model = [m for m in model if m is not None]\n",
    "                if not model:\n",
    "                    print(f\"  Skipping {block_key} - all models are None\")\n",
    "                    continue\n",
    "                preds = np.mean([m.predict(block_df[features]) for m in model], axis=0)\n",
    "            else:\n",
    "                if model is None:\n",
    "                    print(f\"  Skipping {block_key} - model is None\")\n",
    "                    continue\n",
    "                preds = model.predict(block_df[features])\n",
    "\n",
    "            block_df['prediction'] = preds\n",
    "            forecast_rows.append(block_df[['id', 'd', 'prediction']])\n",
    "\n",
    "    if not forecast_rows:\n",
    "        print(\"No forecast blocks available for evaluation period (d1942–1969)\")\n",
    "        return pd.DataFrame(columns=['id', 'd', 'prediction'])\n",
    "\n",
    "    return pd.concat(forecast_rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c30a1796-19de-42af-867e-567497c2e708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features...\n",
      "Shape after transformation: (853720, 26)\n",
      "Creating rolling features...\n",
      "Shape after transformation: (853720, 36)\n",
      "Creating calendar features...\n",
      "Shape after transformation: (853720, 42)\n",
      "Creating price features...\n",
      "Shape after transformation: (853720, 47)\n",
      "Cleaning up event columns...\n",
      "Encoded event_name_1\n",
      "Encoded event_type_1\n",
      "Encoded event_name_2\n",
      "Encoded event_type_2\n",
      "All features created successfully!\n",
      "\n",
      "Evaluating on final holdout (d1914–1941)...\n",
      "\n",
      "Final Holdout RMSE (d1914–1941): 0.0611\n",
      "Submission file saved to final_submission.csv\n"
     ]
    }
   ],
   "source": [
    "future_df = run_feature_engineering(future_df)\n",
    "\n",
    "generate_submission(\n",
    "    final_models,\n",
    "    df=sales_long_recent,\n",
    "    features=FEATURES,\n",
    "    target=TARGET,\n",
    "    future_df=future_df\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e2ee5-61cd-4863-91c4-2ae198d72625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
